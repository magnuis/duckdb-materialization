{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "new_method_df = pd.read_csv(os.curdir + '/results/single-queries/tpch/2025-05-13-22H/results.csv')\n",
    "old_method_df = pd.read_csv(os.curdir + '/results/single-queries/tpch/2025-05-10-15H/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_avg_and_uncertainty(\n",
    "        df:pd.DataFrame, \n",
    "        time_columns:list[str],\n",
    "        avg_col_name:str,\n",
    "        uncertainty_col_name:str\n",
    "    ) -> pd.DataFrame:\n",
    "    def _compute_for_row(row):\n",
    "        # Pull out the execution time values\n",
    "        times = row[time_columns].astype(float).values\n",
    "        \n",
    "        # Calculate mean\n",
    "        mean_val = times.mean()\n",
    "\n",
    "        # Get standard deviation\n",
    "        std_dev = times.std(ddof=1)\n",
    "\n",
    "        # Standard error of the mean\n",
    "        std_error = std_dev / math.sqrt(len(times))\n",
    "\n",
    "        # Decide how many decimal places to keep\n",
    "        decimals = 0\n",
    "        if std_error > 0:\n",
    "            decimals = -int(math.floor(math.log10(std_error)))\n",
    "        \n",
    "        # Round accordingly\n",
    "        rounded_error = round(std_error, decimals)\n",
    "        rounded_mean = round(mean_val, decimals)\n",
    "\n",
    "        return pd.Series({\"Average\": rounded_mean, \"Uncertainty\": rounded_error})\n",
    "\n",
    "    # Apply per-row function to the df\n",
    "    df[[avg_col_name, uncertainty_col_name]] = df.apply(_compute_for_row, axis=1)\n",
    "    return df\n",
    "\n",
    "# Get rounded mean and uncertainty for both result dfs\n",
    "new_method_df = add_avg_and_uncertainty(\n",
    "    df=new_method_df,\n",
    "    time_columns=[f\"Iteration {i}\" for i in range(1, 5)],\n",
    "    avg_col_name=\"New Method, Time\",\n",
    "    uncertainty_col_name=\"New Method, Uncertainty\"\n",
    ")\n",
    "old_method_df = add_avg_and_uncertainty(\n",
    "    df=old_method_df,\n",
    "    time_columns=[f\"Iteration {i}\" for i in range(1, 5)],\n",
    "    avg_col_name=\"Old Method, Time\",\n",
    "    uncertainty_col_name=\"Old Method, Uncertainty\"\n",
    ")\n",
    "new_method_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop individual query execution time columns\n",
    "# Execution time columns\n",
    "new_method_df.drop(columns=[f\"Iteration {i}\" for i in range(5)] + [\"Average (last 4 runs)\"], inplace=True)\n",
    "old_method_df.drop(columns=[f\"Iteration {i}\" for i in range(5)] + [\"Average (last 4 runs)\"], inplace=True)\n",
    "\n",
    "# Set index columns\n",
    "new_method_df.set_index([\"Query\", \"Materialization\"], inplace=True)\n",
    "old_method_df.set_index([\"Query\", \"Materialization\"], inplace=True)\n",
    "\n",
    "# Merge\n",
    "results_df = new_method_df.join(old_method_df, on=[\"Query\", \"Materialization\"])\n",
    "\n",
    "# Reset index\n",
    "results_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column telling which method is faster (with uncertainty)\n",
    "def label_fastest_method(df):\n",
    "    time_col_new = \"New Method, Time\"\n",
    "    time_col_old = \"Old Method, Time\"\n",
    "    uncertainty_col_new = \"New Method, Uncertainty\"\n",
    "    uncertainty_col_old = \"Old Method, Uncertainty\"\n",
    "\n",
    "    new_upper = df[time_col_new] + df[uncertainty_col_new]\n",
    "    new_lower = df[time_col_new] - df[uncertainty_col_new]\n",
    "    old_upper = df[time_col_old] + df[uncertainty_col_old]\n",
    "    old_lower = df[time_col_old] - df[uncertainty_col_old]\n",
    "    \n",
    "    is_new_faster = new_upper < old_lower\n",
    "    is_old_faster = old_upper < new_lower\n",
    "\n",
    "    df[\"Fastest Method\"] = np.select(\n",
    "        [is_new_faster, is_old_faster],\n",
    "        [\"New\", \"Old\"],\n",
    "        default=\"Uncertain\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "results_df = label_fastest_method(results_df)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add column with time difference and uncertainty\n",
    "results_df['Time Difference'] = results_df['New Method, Time'] - results_df['Old Method, Time']\n",
    "results_df[\"Time Difference, Uncertainty\"] = results_df['New Method, Uncertainty']**2 + results_df['Old Method, Uncertainty']**2\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the materialization column into an actual list\n",
    "def parse_materialization(x):\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    try:\n",
    "        # Safely evaluate Python literal (e.g. \"['str1', 'str2']\") into a list\n",
    "        return ast.literal_eval(x)\n",
    "    except (ValueError, SyntaxError):\n",
    "        # Fallback: leave it unchanged or handle differently\n",
    "        return x\n",
    "    \n",
    "\n",
    "results_df[\"Materialization\"] = results_df[\"Materialization\"].apply(\n",
    "    parse_materialization)\n",
    "\n",
    "# Add length of materialization\n",
    "results_df['Materialization Length'] = results_df['Materialization'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 0, 1, 2, and 3 columns materialized\n",
    "m0_df = results_df[results_df[\"Materialization Length\"] == 0]\n",
    "m1_df = results_df[results_df[\"Materialization Length\"] == 1]\n",
    "m2_df = results_df[results_df[\"Materialization Length\"] == 2]\n",
    "m3_df = results_df[results_df[\"Materialization Length\"] == 3]\n",
    "m0_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastest_counts = results_df['Fastest Method'].value_counts()\n",
    "print(\"Overall\")\n",
    "print(fastest_counts)\n",
    "\n",
    "fastest_counts = m0_df['Fastest Method'].value_counts()\n",
    "print(\"-------------------------\")\n",
    "print(\"0 columns materialized\")\n",
    "print(fastest_counts)\n",
    "\n",
    "fastest_counts = m1_df['Fastest Method'].value_counts()\n",
    "print(\"-------------------------\")\n",
    "print(\"1 columns materialized\")\n",
    "print(fastest_counts)\n",
    "\n",
    "fastest_counts = m2_df['Fastest Method'].value_counts()\n",
    "print(\"-------------------------\")\n",
    "print(\"2 columns materialized\")\n",
    "print(fastest_counts)\n",
    "\n",
    "fastest_counts = m3_df['Fastest Method'].value_counts()\n",
    "print(\"-------------------------\")\n",
    "print(\"3 columns materialized\")\n",
    "print(fastest_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sum = results_df['New Method, Time'].sum()\n",
    "old_sum = results_df['Old Method, Time'].sum()\n",
    "\n",
    "print(\"Overall\")\n",
    "print(f\"New Method sum: {new_sum}\")\n",
    "print(f\"Old Method sum: {old_sum}\")\n",
    "\n",
    "new_sum = m0_df['New Method, Time'].sum()\n",
    "old_sum = m0_df['Old Method, Time'].sum()\n",
    "print(\"-------------------------\")\n",
    "print(\"0 columns materialized\")\n",
    "print(f\"New Method sum: {new_sum}\")\n",
    "print(f\"Old Method sum: {old_sum}\")\n",
    "\n",
    "new_sum = m1_df['New Method, Time'].sum()\n",
    "old_sum = m1_df['Old Method, Time'].sum()\n",
    "print(\"-------------------------\")\n",
    "print(\"1 columns materialized\")\n",
    "print(f\"New Method sum: {new_sum}\")\n",
    "print(f\"Old Method sum: {old_sum}\")\n",
    "\n",
    "new_sum = m2_df['New Method, Time'].sum()\n",
    "old_sum = m2_df['Old Method, Time'].sum()\n",
    "print(\"-------------------------\")\n",
    "print(\"2 columns materialized\")\n",
    "print(f\"New Method sum: {new_sum}\")\n",
    "print(f\"Old Method sum: {old_sum}\")\n",
    "\n",
    "new_sum = m3_df['New Method, Time'].sum()\n",
    "old_sum = m3_df['Old Method, Time'].sum()\n",
    "print(\"-------------------------\")\n",
    "print(\"3 columns materialized\")\n",
    "print(f\"New Method sum: {new_sum}\")\n",
    "print(f\"Old Method sum: {old_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_materialization(df: pd.DataFrame):\n",
    "    agg_df = df.groupby(\"Materialization Length\").agg(\n",
    "        Sum_Time_Diff=(\"Time Difference\", \"sum\"),\n",
    "        Time_Diff_Uncertainty=(\"Time Difference, Uncertainty\", lambda x: (x**2).sum()),\n",
    "        New_Fastest_Count=('Fastest Method', lambda x: (x == 'New').sum()),\n",
    "        Old_Fastest_Count=('Fastest Method', lambda x: (x == 'Old').sum()),\n",
    "        Uncertain_Fastest_Count=('Fastest Method', lambda x: (x == 'Uncertain').sum())\n",
    "    )\n",
    "\n",
    "    agg_df[\"Combined_Uncertainty\"] = np.sqrt(agg_df[\"Time_Diff_Uncertainty\"])\n",
    "    agg_df.drop(columns=[\"Time_Diff_Uncertainty\"], inplace=True)\n",
    "\n",
    "    def _round_row(row):\n",
    "        unc = row[\"Combined_Uncertainty\"]\n",
    "        decimals = 0\n",
    "        if unc > 0:\n",
    "            decimals = -int(math.floor(np.log10(unc)))\n",
    "        \n",
    "        row[\"Rounded_Uncertainty\"] = round(unc, decimals)\n",
    "        row[\"Rounded_Sum_Time_Diff\"] = round(row[\"Sum_Time_Diff\"], decimals)\n",
    "\n",
    "        return row\n",
    "    return agg_df.apply(_round_row, axis=1)\n",
    "\n",
    "grouped_by_materialization = group_by_materialization(results_df)\n",
    "grouped_by_materialization.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Query and Materialization Length\n",
    "grouped_by_query_and_materialization = results_df.groupby(['Query', 'Materialization Length']).agg(\n",
    "    Sum_Time_Difference=('Time Difference', 'sum'),\n",
    "    New_Fastest_Count=('Fastest Method', lambda x: (x == 'New').sum()),\n",
    "    Old_Fastest_Count=('Fastest Method', lambda x: (x == 'Old').sum()),\n",
    "    Uncertain_Fastest_Count=('Fastest Method', lambda x: (x == 'Uncertain').sum())\n",
    ").reset_index()\n",
    "\n",
    "grouped_by_query_and_materialization[(grouped_by_query_and_materialization[\"Sum_Time_Difference\"] < -5) | (grouped_by_query_and_materialization[\"Sum_Time_Difference\"] > 5)].sort_values(\"Sum_Time_Difference\",ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_query = grouped_by_query_and_materialization.groupby(['Query']).agg(\n",
    "    Sum_Time_Difference=('Sum_Time_Difference', 'sum'),\n",
    "    New_Fastest_Count=('New_Fastest_Count', 'sum'),\n",
    "    Old_Fastest_Count=('Old_Fastest_Count', 'sum'),\n",
    "    Uncertain_Fastest_Count=('Uncertain_Fastest_Count', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "grouped_by_query.sort_values(\"Sum_Time_Difference\").head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sorted(results_df[results_df[\"Fastest Method\"] == \"New\"][\"Query\"].unique()\n",
    "))\n",
    "# results_df[(results_df[\"Fastest Method\"] == \"New\") & (~results_df['Query'].isin(['q1', 'q18', 'q21']))].sort_values(\"Time Difference\", ascending=False).head(50)\n",
    "# results_df[(results_df[\"Fastest Method\"] == \"Old\") & (~results_df['Query'].isin(['q8', 'q7', 'q20', 'q11', 'q9', 'q21', 'q17', 'q2', 'q10']))].sort_values(\"Time Difference\", ascending=False).head(50)\n",
    "results_df[results_df[\"Fastest Method\"] == \"Old\"].sort_values(\"Time Difference\", ascending=False).head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
