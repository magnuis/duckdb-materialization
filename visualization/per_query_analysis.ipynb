{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "\n",
    "import testing.tpch.setup as tpch_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small dataset, 500 queries - m1, m2, m3 ...\n",
    "RESULTS_PATH = f\"{os.path.curdir}/results/load-based-N-fields/tpch/2025-03-26-15H/\"\n",
    "\n",
    "results_df = pd.read_csv(RESULTS_PATH + \"meta_results.csv\")\n",
    "results_df = results_df[[\"Test\", \"Load\", \"Total query time\",\n",
    "                         \"Materialized Columns\", \"Materialization\"]]\n",
    "\n",
    "results_df.head(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only look at load-based tests\n",
    "results_df = results_df[results_df[\"Test\"] != \"full_materialization\"]\n",
    "results_df = results_df[results_df[\"Test\"] != \"schema_based_materialization\"]\n",
    "results_df = results_df[results_df[\"Test\"] != \"load_based_m20\"]\n",
    "results_df = results_df[results_df[\"Test\"] != \"load_based_m25\"]\n",
    "results_df = results_df[results_df[\"Test\"] != \"load_based_m30\"]\n",
    "results_df = results_df[results_df[\"Test\"] != \"load_based_m35\"]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the materialized column\n",
    "results_df[\"Materialized Column\"] = results_df.apply(\n",
    "    lambda row: row[\"Materialization\"].strip('[').strip(']').split(', ')[-1].strip(\"'\"), axis=1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the datatype of each materialized column from COLUMN_MAP\n",
    "results_df[\"Column Type\"] = results_df.apply(\n",
    "    lambda row: tpch_setup.COLUMN_MAP[row[\"Materialized Column\"]][\"type\"] \n",
    "    if row[\"Materialized Column\"] in tpch_setup.COLUMN_MAP else \"Unknown\", \n",
    "    axis=1)\n",
    "\n",
    "\n",
    "\n",
    "scale_factor = 0.5\n",
    "tpch_table_sizes = {\n",
    "    \"customer\": int(150000 * scale_factor),\n",
    "    \"lineitem\": int(6000000 * scale_factor),\n",
    "    \"orders\": int(1500000 * scale_factor),\n",
    "    \"part\": int(200000 * scale_factor),\n",
    "    \"partsupp\": int(800000 * scale_factor),\n",
    "    \"supplier\": int(10000 * scale_factor),\n",
    "    \"nation\": 25,  # Not scaled\n",
    "    \"region\": 5    # Not scaled\n",
    "}\n",
    "\n",
    "\n",
    "def get_table_size(column_name):\n",
    "    if column_name.startswith(\"c_\"):\n",
    "        return tpch_table_sizes[\"customer\"]\n",
    "    elif column_name.startswith(\"l_\"):\n",
    "        return tpch_table_sizes[\"lineitem\"]\n",
    "    elif column_name.startswith(\"o_\"):\n",
    "        return tpch_table_sizes[\"orders\"]\n",
    "    elif column_name.startswith(\"p_\"):\n",
    "        return tpch_table_sizes[\"part\"]\n",
    "    elif column_name.startswith(\"ps_\"):\n",
    "        return tpch_table_sizes[\"partsupp\"]\n",
    "    elif column_name.startswith(\"s_\"):\n",
    "        return tpch_table_sizes[\"supplier\"]\n",
    "    elif column_name.startswith(\"n_\"):\n",
    "        return tpch_table_sizes[\"nation\"]\n",
    "    elif column_name.startswith(\"r_\"):\n",
    "        return tpch_table_sizes[\"region\"]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "results_df[\"Table Size\"] = results_df[\"Materialized Column\"].apply(get_table_size)\n",
    "results_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(10):\n",
    "\n",
    "    filename = f\"q4_m400_l{n}.csv\"\n",
    "    load_df = pd.read_csv(os.path.join(RESULTS_PATH, filename))\n",
    "\n",
    "    load_df.drop(columns=[\"schema_based_materialization\", \"full_materialization\",\n",
    "                     \"load_based_m20\", \"load_based_m25\", \"load_based_m30\", \"load_based_m35\"], inplace=True)\n",
    "\n",
    "    if \"Unnamed: 0\" in load_df.columns:\n",
    "        load_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "    cols_to_process = [col for col in load_df.columns if col != 'q']\n",
    "\n",
    "      # Compute means and sums per query\n",
    "    df_mean = load_df.groupby('q')[cols_to_process].mean()\n",
    "    df_sum = load_df.groupby('q')[cols_to_process].sum()\n",
    "\n",
    "\n",
    "    # Transpose and label\n",
    "    df_mean_t = df_mean.transpose().reset_index().rename(columns={'index': 'Test'})\n",
    "    df_sum_t = df_sum.transpose().reset_index().rename(columns={'index': 'Test'})\n",
    "\n",
    "    # Now, df_transposed has columns: \"Test\", \"q1\", \"q2\", ..., \"q21\"\n",
    "    matching_indices = results_df[results_df[\"Load\"] == n].index\n",
    "\n",
    "    for idx in matching_indices:\n",
    "        test_name = results_df.at[idx, \"Test\"]\n",
    "\n",
    "        row_mean = df_mean_t[df_mean_t[\"Test\"] == test_name]\n",
    "        row_sum = df_sum_t[df_sum_t[\"Test\"] == test_name]\n",
    "\n",
    "        if not row_mean.empty and not row_sum.empty:\n",
    "            for i in range(1, 22):\n",
    "                q_col = f\"q{i}\"\n",
    "                if q_col in row_mean.columns:\n",
    "                    results_df.at[idx, f\"{q_col}_mean\"] = row_mean.iloc[0][q_col]\n",
    "                    results_df.at[idx, f\"{q_col}_sum\"] = row_sum.iloc[0][q_col]\n",
    "        else:\n",
    "            print(f\"No match found for Test='{test_name}' at Load={n}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = tpch_setup.QUERIES\n",
    "\n",
    "results_df_q = results_df.copy()\n",
    "results_df_q = results_df_q[[\"Load\", \"Materialized Columns\",\"Materialized Column\", \"Column Type\", \"Table Size\", \"q1_mean\", \"q1_sum\", \"q2_mean\", \"q2_sum\", \"q3_mean\", \"q3_sum\", \"q4_mean\", \"q4_sum\", \"q6_mean\", \"q6_sum\", \"q7_mean\", \"q7_sum\", \"q8_mean\", \"q8_sum\", \"q9_mean\", \"q9_sum\", \"q10_mean\", \"q10_sum\", \"q11_mean\", \"q11_sum\", \"q12_mean\", \"q12_sum\", \"q13_mean\", \"q13_sum\", \"q14_mean\", \"q14_sum\", \"q15_mean\", \"q15_sum\", \"q16_mean\", \"q16_sum\", \"q17_mean\", \"q17_sum\", \"q18_mean\", \"q18_sum\", \"q19_mean\", \"q19_sum\", \"q20_mean\", \"q20_sum\", \"q21_mean\", \"q21_sum\"]]\n",
    "results_df_q.sort_values([\"Load\", \"Materialized Columns\"], inplace=True)\n",
    "\n",
    "\n",
    "# Make a new 21 new columns that represent the mean time in the previous materialization\n",
    "for i in range(1, 22):\n",
    "    if i == 5:\n",
    "        continue\n",
    "    # Apply the condition row by row\n",
    "    q_col_mean = f\"q{i}_mean\"\n",
    "    q_col_sum = f\"q{i}_sum\"\n",
    "    # 1) compute the diff across all rows\n",
    "    results_df_q[f\"Pre-materialization q{i} mean\"] = results_df_q[q_col_mean].shift(1)\n",
    "    results_df_q[f\"Pre-materialization q{i} sum\"] = results_df_q[q_col_sum].shift(1)\n",
    "\n",
    "\n",
    "# Make a new 21 new columns that represent the reduction in execution time for each query\n",
    "for i in range(1, 22):\n",
    "    if i == 5:\n",
    "        continue\n",
    "    # Apply the condition row by row\n",
    "    q_col_mean = f\"q{i}_mean\"\n",
    "\n",
    "    # 1) compute the diff across all rows\n",
    "    results_df_q[f\"Time gain q{i} mean\"] = -results_df_q[q_col_mean].diff()\n",
    "\n",
    "    # 2) mask out the rows where you don't care about time‐gain\n",
    "    mask = results_df_q[\"Materialized Column\"].isin(queries[f\"q{i}\"].columns_used())\n",
    "    results_df_q.loc[~mask, f\"Time gain q{i} mean\"] = np.nan\n",
    "    \n",
    "\n",
    "\n",
    "# For time gain on sum:\n",
    "for i in range(1, 22):\n",
    "    if i == 5:\n",
    "        continue\n",
    "    q_col_sum = f\"q{i}_sum\"\n",
    "\n",
    "    # 1) compute the diff across all rows\n",
    "    results_df_q[f\"Time gain q{i} sum\"] = -results_df_q[q_col_sum].diff()\n",
    "\n",
    "    # 2) mask out the rows where you don't care about time‐gain\n",
    "    mask = results_df_q[\"Materialized Column\"].isin(queries[f\"q{i}\"].columns_used())\n",
    "    results_df_q.loc[~mask, f\"Time gain q{i} sum\"] = np.nan\n",
    "\n",
    "# TODO: Implement no materialization\n",
    "results_df_q = results_df_q[results_df_q[\"Materialized Columns\"] != 1]\n",
    "# Get base columns and dynamically build query time gain columns\n",
    "base_cols = [\"Materialized Column\", \"Load\", \"Materialized Columns\", \"Column Type\", \"Table Size\"]\n",
    "time_gain_cols = [f\"Time gain q{i} {stat}\" for i in range(1,22) if i != 5 for stat in [\"mean\", \"sum\"]]\n",
    "pre_mat_cols = [f\"Pre-materialization q{i} {stat}\" for i in range(1,22) if i != 5 for stat in [\"mean\", \"sum\"]]\n",
    "results_df_q[base_cols + time_gain_cols + pre_mat_cols].head(50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_results_df_q = pd.DataFrame()\n",
    "for index, row in results_df_q.iterrows():\n",
    "    for i in range(1, 22):\n",
    "        if i == 5:  # Skip q5 since it was excluded earlier\n",
    "            continue\n",
    "\n",
    "\n",
    "        new_row = {\n",
    "            'Load': row['Load'], \n",
    "            'Materialized Column': row['Materialized Column'],\n",
    "            'Materialized Columns': row['Materialized Columns'],\n",
    "            \"Column Type\": row[\"Column Type\"],\n",
    "            \"Table Size\": row[\"Table Size\"],\n",
    "            'Query': f'q{i}',\n",
    "            'Time gain mean': row[f'Time gain q{i} mean'],\n",
    "            'Time gain sum': row[f'Time gain q{i} sum'],\n",
    "            \"Pre-materialization mean\": row[f\"Pre-materialization q{i} mean\"],\n",
    "            \"Pre-materialization sum\": row[f\"Pre-materialization q{i} sum\"]\n",
    "        }\n",
    "        expanded_results_df_q = pd.concat([expanded_results_df_q, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "def get_field_frequency_for_query(query_name, materialized_column):\n",
    "    q = queries[query_name]\n",
    "    cols = q.columns_used()\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_join_frequency_for_query(query_name, materialized_column):\n",
    "    q = queries[query_name]\n",
    "    cols = q.columns_used_with_position()[\"join\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_where_frequency_for_query(query_name, materialized_column):\n",
    "    q = queries[query_name]\n",
    "    cols = q.columns_used_with_position()[\"where\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_select_frequency_for_query(query_name, materialized_column):\n",
    "    q = queries[query_name]\n",
    "    cols = q.columns_used_with_position()[\"select\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "\n",
    "\n",
    "queries = tpch_setup.QUERIES\n",
    "\n",
    "expanded_results_df_q[\"Total Frequency\"] = expanded_results_df_q.apply(\n",
    "    lambda row: get_field_frequency_for_query(row[\"Query\"], row[\"Materialized Column\"]), axis=1\n",
    ")\n",
    "\n",
    "expanded_results_df_q[\"Join Frequency\"] = expanded_results_df_q.apply(\n",
    "    lambda row: get_field_join_frequency_for_query(row[\"Query\"], row[\"Materialized Column\"]), axis=1\n",
    ")\n",
    "\n",
    "expanded_results_df_q[\"Where Frequency\"] = expanded_results_df_q.apply(\n",
    "    lambda row: get_field_where_frequency_for_query(row[\"Query\"], row[\"Materialized Column\"]), axis=1\n",
    ")\n",
    "\n",
    "expanded_results_df_q[\"Select Frequency\"] = expanded_results_df_q.apply(\n",
    "    lambda row: get_field_select_frequency_for_query(row[\"Query\"], row[\"Materialized Column\"]), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "temp_df = expanded_results_df_q.dropna(subset=[\"Time gain mean\", \"Time gain sum\"])\n",
    "# temp_df.sort_values([\"Select Frequency\", \"Query\", \"Materialized Columns\"], ascending=False).head(50)\n",
    "temp_df[(temp_df[\"Select Frequency\"] > temp_df[\"Join Frequency\"]) & (temp_df[\"Select Frequency\"] > temp_df[\"Where Frequency\"])].sort_values(\"Time gain mean\", ascending=False).head(50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_new = temp_df[[\"Load\", \"Query\"]]\n",
    "\n",
    "# Count number of materialized columns per load/query combination\n",
    "temp_df_new = temp_df_new.groupby([\"Load\", \"Query\"]).size().reset_index(name='count')\n",
    "temp_df_new.sort_values(\"count\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Datatype\n",
    "* Tabellstørrelse\n",
    "* Kjøretid før materialisering\n",
    "* Er motparten materialisert?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Materialized column\n",
    "Materialized columns\n",
    "Query\n",
    "Time gain\n",
    "Time\n",
    "Prev time\n",
    "\n",
    "Rangere materialiseringene innad i spørring\n",
    "Lage percentiler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
