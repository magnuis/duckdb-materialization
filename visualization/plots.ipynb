{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Small dataset, 500 queries\n",
    "RESULTS_PATH = \"../results/tpch/2025-03-06-9H\"\n",
    "# Small dataset, 100 queries\n",
    "# RESULTS_PATH = \"../results/tpch/2025-03-10-14H\"\n",
    "# Small dataset, 500 queries (fewer param permutations)\n",
    "# RESULTS_PATH = \"../results/tpch/2025-03-05-15H\"\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "meta_results = pd.read_csv(RESULTS_PATH + \"/meta_results.csv\")\n",
    "\n",
    "# Function to count the number of materialized fields from the string representation\n",
    "def count_materialized_fields(s: str):\n",
    "    try:\n",
    "        # Converts the string representation to a python list\n",
    "        fields = ast.literal_eval(s)\n",
    "        return len(fields)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Create a new column with the number of materialized fields\n",
    "meta_results[\"num_materialized_fields\"] = meta_results[\"Materialization\"].apply(count_materialized_fields)\n",
    "\n",
    "\n",
    "# Exclude rows where Test is full_materialization\n",
    "meta_results_no_full = meta_results[meta_results[\"Test\"] != \"full_materialization\"]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(meta_results_no_full[\"num_materialized_fields\"], meta_results_no_full[\"Database size\"])\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Database Size\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Database Size\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(meta_results[\"num_materialized_fields\"], meta_results[\"Time taken\"])\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Time Taken to Materialize\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Time Taken to Materialize\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = meta_results[(meta_results[\"Total query time\"] > 0) & (meta_results[\"Test\"] != \"full_materialization\") & (meta_results[\"Test\"] != \"schema_based_materialization\")]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(subset[\"num_materialized_fields\"], subset[\"Total query time\"])\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Total Query Time\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Total Query Time\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = meta_results[(meta_results[\"Total query time\"] > 0)]\n",
    "# Subset rows where Test starts with \"load_based_t\"\n",
    "load_based = subset[subset[\"Test\"].str.startswith(\"load_based_t\")]\n",
    "\n",
    "# Subset rows with Test equal to \"schema_based_materialization\"\n",
    "schema_based = subset[subset[\"Test\"] == \"schema_based_materialization\"]\n",
    "\n",
    "# Merge the two dataframes on the columns \"Query proportion\", \"Majority proportion\", and \"Load\"\n",
    "merged = pd.merge(\n",
    "    load_based,\n",
    "    schema_based,\n",
    "    on=[\"Query proportion\", \"Majority proportion\", \"Load\"],\n",
    "    suffixes=('_load', '_schema')\n",
    ")\n",
    "# Compute the ratio between the total query time of the load_based row and the corresponding schema_based row\n",
    "merged[\"query_time_ratio\"] = merged[\"Total query time_load\"] / merged[\"Total query time_schema\"]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(merged[\"num_materialized_fields_load\"], merged[\"query_time_ratio\"])\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Query Time Ratio (load_based / schema_based)\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Query Time Ratio\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# Define color mapping for all tests (adjust the colors as needed)\n",
    "colors = {\n",
    "    \"schema_based_materialization\": \"#55A868\",\n",
    "    \"load_based_t0.33\": \"#C4AD66\",\n",
    "    \"load_based_t0.3\": \"#C44E52\",\n",
    "    \"load_based_t0.35\": \"#CC6677\",   \n",
    "    \"load_based_t0.4\": \"#DDCC77\",\n",
    "    \"load_based_t0.45\": \"#8172B3\",\n",
    "    \"load_based_t0.5\": \"#AA4499\",\n",
    "    \"load_based_t0.55\": \"#882255\",\n",
    "    \"load_based_t0.6\": \"#332288\",\n",
    "    \"load_based_t0.65\": \"#6699CC\",\n",
    "    \"load_based_t0.7\": \"#88CCEE\",\n",
    "    \"load_based_t0.75\": \"#44BB99\",\n",
    "    \"load_based_t0.8\": \"#117733\",\n",
    "    \"load_based_t0.85\": \"#999933\",\n",
    "}\n",
    "\n",
    "# Define test groups for the three plots\n",
    "plot_tests = {\n",
    "    1: [\"schema_based_materialization\", \"load_based_t0.3\", \"load_based_t0.35\", \"load_based_t0.4\", \"load_based_t0.45\"],\n",
    "    2: [\"schema_based_materialization\", \"load_based_t0.5\", \"load_based_t0.55\", \"load_based_t0.6\", \"load_based_t0.65\"],\n",
    "    3: [\"schema_based_materialization\", \"load_based_t0.7\", \"load_based_t0.75\", \"load_based_t0.8\", \"load_based_t0.85\"],\n",
    "    4: [\"schema_based_materialization\", \"load_based_t0.33\", \"load_based_t0.4\", \"load_based_t0.5\"],\n",
    "}\n",
    "\n",
    "# Loop over each plot group and generate a separate figure\n",
    "for plot_num, tests in plot_tests.items():\n",
    "    # Filter the DataFrame for the tests in the current group.\n",
    "    df_current = meta_results[meta_results[\"Test\"].isin(tests)].copy()\n",
    "    \n",
    "    # Create a new column for combination (Query proportion / Majority proportion)\n",
    "    df_current[\"combination\"] = df_current[\"Query proportion\"].astype(str) + \"/\" + df_current[\"Majority proportion\"].astype(str)\n",
    "    \n",
    "    # Group by combination and Test to compute mean, standard deviation, and count.\n",
    "    grouped = df_current.groupby([\"combination\", \"Test\"])[\"Total query time\"] \\\n",
    "                        .agg(mean=\"mean\", std=\"std\", count=\"count\").reset_index()\n",
    "    grouped[\"stderr\"] = grouped[\"std\"] / np.sqrt(grouped[\"count\"])\n",
    "    \n",
    "    # Pivot the DataFrames for means and standard errors\n",
    "    pivot_df = grouped.pivot(index=\"combination\", columns=\"Test\", values=\"mean\").sort_index()\n",
    "    stderr_df = grouped.pivot(index=\"combination\", columns=\"Test\", values=\"stderr\").sort_index()\n",
    "    \n",
    "    # Create a new figure for the current plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    combinations_sorted = pivot_df.index.values\n",
    "    x = np.arange(len(combinations_sorted))\n",
    "    # Dynamically set bar width based on the number of tests in this group.\n",
    "    bar_width = 0.8 / len(tests)\n",
    "    \n",
    "    # Loop over each combination and plot the bars with error bars.\n",
    "    for i, comb in enumerate(combinations_sorted):\n",
    "        # Get the data for the current combination (some tests might be missing).\n",
    "        group_means = pivot_df.loc[comb].dropna()\n",
    "        group_stderr = stderr_df.loc[comb].dropna()\n",
    "        # Sort tests by average total query time (ascending)\n",
    "        sorted_group = group_means.sort_values()\n",
    "        sorted_stderr = group_stderr[sorted_group.index]\n",
    "        # Plot each bar for the sorted tests\n",
    "        for j, test in enumerate(sorted_group.index):\n",
    "            ax.bar(x[i] + j * bar_width, sorted_group[test], bar_width, color=colors[test],\n",
    "                   yerr=sorted_stderr[test], capsize=5)\n",
    "    \n",
    "    # Set x-tick labels centered under each combination group.\n",
    "    ax.set_xticks(x + bar_width * (len(tests) - 1) / 2)\n",
    "    ax.set_xticklabels(combinations_sorted)\n",
    "    ax.set_xlabel(\"Query proportion / Majority proportion\")\n",
    "    ax.set_ylabel(\"Average Total Query Time\")\n",
    "    ax.set_title(f\"Plot {plot_num}: Average Total Query Time Across Combinations\\n(Each Bar is Averaged Over 5 Instances with Uncertainty)\")\n",
    "    ax.grid(True, axis='y')\n",
    "    \n",
    "    # Create a custom legend using the tests defined for this plot.\n",
    "    legend_handles = [mpatches.Patch(color=colors[test], label=test) for test in tests]\n",
    "    ax.legend(handles=legend_handles)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
