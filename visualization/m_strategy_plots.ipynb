{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Small dataset, 500 queries - m1, m2, m3 ...\n",
    "# RESULTS_PATH = \"../results/load-based-N-fields/tpch/2025-03-19-21H\"\n",
    "# Medium dataset (scale 0.5), 500 queries - m1, m2, m3 ...\n",
    "# RESULTS_PATH = \"../results/load-based-N-fields/tpch/2025-03-20-19H\"\n",
    "# results against views\n",
    "# RESULTS_PATH = \"../results/load-based-N-fields/tpch/2025-03-17-8H\"\n",
    "# Medium (scale 0.5), without q5\n",
    "RESULTS_PATH = \"../results/load-based-N-fields/tpch/2025-03-26-15H\"\n",
    "\n",
    "# Read the CSV file\n",
    "meta_results = pd.read_csv(RESULTS_PATH + \"/meta_results.csv\")\n",
    "\n",
    "# Function to count the number of materialized fields from the string representation\n",
    "def count_materialized_fields(s: str):\n",
    "    try:\n",
    "        # Converts the string representation to a python list\n",
    "        fields = ast.literal_eval(s)\n",
    "        return len(fields)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Create a new column with the number of materialized fields\n",
    "meta_results[\"num_materialized_fields\"] = meta_results[\"Materialization\"].apply(count_materialized_fields)\n",
    "\n",
    "\n",
    "# Exclude rows where Test is full_materialization\n",
    "meta_results_no_full = meta_results[(meta_results[\"Test\"] != \"full_materialization\") & (meta_results[\"Test\"] != \"schema_based_materialization\")]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    meta_results_no_full[\"num_materialized_fields\"],\n",
    "    meta_results_no_full[\"Database size\"],\n",
    "    c=meta_results_no_full[\"Load\"],\n",
    "    cmap=plt.cm.get_cmap('tab10', 10))  # 10 discrete colors for values 0-9)\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Database Size (bytes)\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Database Size\")\n",
    "plt.colorbar(scatter, label='Load')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    meta_results_no_full[\"num_materialized_fields\"],\n",
    "    meta_results_no_full[\"Time to prepare db\"],\n",
    "    c=meta_results_no_full[\"Load\"],\n",
    "    cmap=plt.cm.get_cmap('tab10', 10))\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Time Taken to Materialize (s)\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Time Taken to Materialize\")\n",
    "plt.colorbar(scatter, label='Load')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = meta_results[(meta_results[\"Total query time\"] > 0) & (meta_results[\"Test\"] != \"full_materialization\") & (meta_results[\"Test\"] != \"schema_based_materialization\")]\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    subset[\"num_materialized_fields\"],\n",
    "    subset[\"Total query time\"],\n",
    "    c=subset[\"Load\"],\n",
    "    cmap=plt.cm.get_cmap('tab10', 10))\n",
    "\n",
    "plt.colorbar(scatter, label='Load')\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Total Query Time (s)\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Total Query Time\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = meta_results[(meta_results[\"Total query time\"] > 0)]\n",
    "# Subset rows where Test starts with \"load_based_t\"\n",
    "load_based = subset[subset[\"Test\"].str.startswith(\"load_based_m\")]\n",
    "\n",
    "# Subset rows with Test equal to \"schema_based_materialization\"\n",
    "schema_based = subset[subset[\"Test\"] == \"schema_based_materialization\"]\n",
    "\n",
    "# Merge the two dataframes on the columns \"Query proportion\", \"Majority proportion\", and \"Load\"\n",
    "merged = pd.merge(\n",
    "    load_based,\n",
    "    schema_based,\n",
    "    on=[\"Query proportion\", \"Majority proportion\", \"Load\"],\n",
    "    suffixes=('_load', '_schema')\n",
    ")\n",
    "# Compute the ratio between the total query time of the load_based row and the corresponding schema_based row\n",
    "merged[\"query_time_ratio\"] = merged[\"Total query time_load\"] / merged[\"Total query time_schema\"]\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    merged[\"num_materialized_fields_load\"],\n",
    "    merged[\"query_time_ratio\"],\n",
    "    c=merged[\"Load\"],\n",
    "    cmap=plt.cm.get_cmap('tab10', 10))\n",
    "plt.colorbar(scatter, label='Load')\n",
    "\n",
    "plt.axline([16, 0], [16, 1.6], color='red')\n",
    "plt.xlabel(\"Number of Materialized Fields\")\n",
    "plt.ylabel(\"Query Time Ratio (load_based / schema_based)\")\n",
    "plt.title(\"Scatter Plot: Number of Materialized Fields vs. Query Time Ratio\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "\n",
    "# Define new color mapping for all tests (adjust as needed)\n",
    "colors = {\n",
    "    \"schema_based_materialization\": \"#FF7F0E\",  # Bright orange for clear visibility\n",
    "\n",
    "    \"load_based_m0\":  \"#1f77b4\",  # Blue\n",
    "    \"load_based_m1\":  \"#2ca02c\",  # Green\n",
    "    \"load_based_m2\":  \"#d62728\",  # Red\n",
    "    \"load_based_m3\":  \"#9467bd\",  # Purple\n",
    "    \"load_based_m4\":  \"#8c564b\",  # Brown\n",
    "\n",
    "    \"load_based_m5\":  \"#1f77b4\",  # Blue\n",
    "    \"load_based_m6\":  \"#2ca02c\",  # Green\n",
    "    \"load_based_m7\":  \"#d62728\",  # Red\n",
    "    \"load_based_m8\":  \"#9467bd\",  # Purple\n",
    "    \"load_based_m9\":  \"#8c564b\",  # Brown\n",
    "\n",
    "    \"load_based_m10\": \"#1f77b4\",  # Blue\n",
    "    \"load_based_m11\": \"#2ca02c\",  # Green\n",
    "    \"load_based_m12\": \"#d62728\",  # Red\n",
    "    \"load_based_m13\": \"#9467bd\",  # Purple\n",
    "    \"load_based_m14\": \"#8c564b\",  # Brown\n",
    "\n",
    "    \"load_based_m15\": \"#1f77b4\",  # Blue\n",
    "    \"load_based_m20\": \"#2ca02c\",  # Green\n",
    "    \"load_based_m25\": \"#d62728\",  # Red\n",
    "    \"load_based_m30\": \"#9467bd\",  # Purple\n",
    "    \"load_based_m35\": \"#8c564b\",  # Brown\n",
    "}\n",
    "\n",
    "# Define the test order using all keys from the colors dictionary\n",
    "test_order = list(colors.keys())\n",
    "\n",
    "def shorten_label_into_number(test):\n",
    "    if test == \"schema_based_materialization\":\n",
    "        return 16\n",
    "    elif test.startswith(\"load_based_\"):\n",
    "        return int((test.split(\"_\")[-1])[1:])\n",
    "    else:\n",
    "        return test\n",
    "\n",
    "# Filter the DataFrame for the tests in test_order\n",
    "df_current = meta_results[meta_results[\"Test\"].isin(test_order)].copy()\n",
    "\n",
    "# Group by Test to compute statistics for Total query time\n",
    "grouped_total_query_time = df_current.groupby(\"Test\")[\"Total query time\"].agg(\n",
    "    mean=\"mean\", std=\"std\", count=\"count\", max=\"max\", min=\"min\"\n",
    ").reset_index()\n",
    "grouped_total_query_time[\"stderr\"] = grouped_total_query_time[\"std\"] / np.sqrt(grouped_total_query_time[\"count\"])\n",
    "\n",
    "# Ensure that the tests are ordered as in test_order (this line is kept if needed for other purposes)\n",
    "grouped_total_query_time[\"Test\"] = pd.Categorical(\n",
    "    grouped_total_query_time[\"Test\"], categories=test_order, ordered=True\n",
    ")\n",
    "\n",
    "# Instead of sorting by mean, we sort by the numeric value from shorten_label_into_number\n",
    "grouped_total_query_time.sort_values(\n",
    "    \"Test\", key=lambda col: col.map(shorten_label_into_number)\n",
    ", inplace=True)\n",
    "# Helper function to shorten the labels\n",
    "def shorten_label(test):\n",
    "    if test == \"schema_based_materialization\":\n",
    "        return \"s16\"\n",
    "    elif test.startswith(\"load_based_\"):\n",
    "        return test.split(\"_\")[-1]\n",
    "    else:\n",
    "        return test\n",
    "\n",
    "# Create the list of shortened labels\n",
    "short_labels = [shorten_label(test) for test in grouped_total_query_time[\"Test\"]]\n",
    "\n",
    "# Common x positions and bar width\n",
    "x = np.arange(len(grouped_total_query_time))\n",
    "bar_width = 0.6\n",
    "\n",
    "# Define plot configurations in a loop\n",
    "plot_configs = [\n",
    "    {\"mode\": \"errorbar\", \"title\": \"Average Total Query Time for each Test (with Uncertainty)\"},\n",
    "    {\"mode\": \"minmax\", \"title\": \"Total Query Time for each Test (with Min and Max Values)\"}\n",
    "]\n",
    "\n",
    "for config in plot_configs:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    mode = config[\"mode\"]\n",
    "    \n",
    "    if mode == \"errorbar\":\n",
    "        # Plot bars with error bars for standard error\n",
    "        ax.bar(\n",
    "            x,\n",
    "            grouped_total_query_time[\"mean\"],\n",
    "            bar_width,\n",
    "            color=[colors[test] for test in grouped_total_query_time[\"Test\"]],\n",
    "            yerr=grouped_total_query_time[\"stderr\"],\n",
    "            capsize=5\n",
    "        )\n",
    "    elif mode == \"minmax\":\n",
    "        # Plot bars without error bars\n",
    "        ax.bar(\n",
    "            x,\n",
    "            grouped_total_query_time[\"mean\"],\n",
    "            bar_width,\n",
    "            color=[colors[test] for test in grouped_total_query_time[\"Test\"]],\n",
    "            capsize=5\n",
    "        )\n",
    "        # Overlay dashed lines and markers for min and max values\n",
    "        for i, (_, row) in enumerate(grouped_total_query_time.iterrows()):\n",
    "            ax.plot([x[i], x[i]], [row[\"min\"], row[\"max\"]],\n",
    "                    linestyle=\"--\", color=\"black\", linewidth=1.5)\n",
    "            ax.scatter(x[i], row[\"min\"], color=\"black\", marker=\"v\", s=50)\n",
    "            ax.scatter(x[i], row[\"max\"], color=\"black\", marker=\"^\", s=50)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(short_labels, rotation=45)\n",
    "    ax.set_xlabel(\"Test\")\n",
    "    ax.set_ylabel(\"Average Total Query Time (s)\")\n",
    "    ax.set_title(config[\"title\"])\n",
    "    ax.grid(True, axis='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test order using all keys from the colors dictionary\n",
    "test_order = list(colors.keys())\n",
    "\n",
    "\n",
    "# Loop over each load value (0 to 9)\n",
    "for load in range(10):\n",
    "    # Filter the DataFrame for the current load and tests in test_order\n",
    "    df_load = meta_results[(meta_results[\"Load\"] == load) & (meta_results[\"Test\"].isin(test_order))].copy()\n",
    "    \n",
    "    # Ensure tests are ordered as defined in test_order\n",
    "    df_load[\"Test\"] = pd.Categorical(df_load[\"Test\"], categories=test_order, ordered=True)\n",
    "\n",
    "    # Instead of sorting by mean, we sort by the numeric value from shorten_label_into_number\n",
    "    df_load = df_load.sort_values(by=\"Test\", key=lambda col: col.map(shorten_label_into_number))\n",
    "    \n",
    "    # Create shortened labels for x-axis\n",
    "    short_labels = [shorten_label(test) for test in df_load[\"Test\"]]\n",
    "    \n",
    "    # Define positions and bar width\n",
    "    x = np.arange(len(df_load))\n",
    "    bar_width = 0.6\n",
    "\n",
    "    # Create a new figure for the current load\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot bars using raw \"Total query time\" values\n",
    "    ax.bar(\n",
    "        x,\n",
    "        df_load[\"Total query time\"],\n",
    "        bar_width,\n",
    "        color=[colors[test] for test in df_load[\"Test\"]]\n",
    "    )\n",
    "    \n",
    "    # Set x-axis labels and titles\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(short_labels, rotation=45)\n",
    "    ax.set_xlabel(\"Test\")\n",
    "    ax.set_ylabel(\"Total Query Time (s)\")\n",
    "    ax.set_title(f\"Load {load}: Total Query Time\")\n",
    "    ax.grid(True, axis=\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Magnus\n",
    "    Q15 - 122\n",
    "    q20 - 101 - Spør om L\n",
    "    Q9 - 89 - Spør litt om L\n",
    "    Q12 - 88 - Spør mye om L \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
