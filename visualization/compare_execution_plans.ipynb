{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from testing.twitter import setup\n",
    "\n",
    "QUERIES = setup.QUERIES\n",
    "COLUMN_MAP = setup.COLUMN_MAP\n",
    "\n",
    "RESULTS_PATH = os.curdir + \"/results/single-queries/tpch/2025-05-10-15H/\"\n",
    "\n",
    "results_df = pd.read_csv(RESULTS_PATH + '/expanded_results.csv')\n",
    "\n",
    "if \"Unnamed: 0\" in results_df.columns:\n",
    "    results_df = results_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add table size to results\n",
    "scale_factor = 0.5\n",
    "tpch_table_sizes = {\n",
    "    \"customer\": int(150000 * scale_factor),\n",
    "    \"lineitem\": int(6000000 * scale_factor),\n",
    "    \"orders\": int(1500000 * scale_factor),\n",
    "    \"part\": int(200000 * scale_factor),\n",
    "    \"partsupp\": int(800000 * scale_factor),\n",
    "    \"supplier\": int(10000 * scale_factor),\n",
    "    \"nation\": 25,  # Not scaled\n",
    "    \"region\": 5    # Not scaled\n",
    "}\n",
    "\n",
    "\n",
    "def get_table_size(column_name):\n",
    "    if column_name.startswith(\"c_\"):\n",
    "        return tpch_table_sizes[\"customer\"]\n",
    "    elif column_name.startswith(\"l_\"):\n",
    "        return tpch_table_sizes[\"lineitem\"]\n",
    "    elif column_name.startswith(\"o_\"):\n",
    "        return tpch_table_sizes[\"orders\"]\n",
    "    elif column_name.startswith(\"p_\"):\n",
    "        return tpch_table_sizes[\"part\"]\n",
    "    elif column_name.startswith(\"ps_\"):\n",
    "        return tpch_table_sizes[\"partsupp\"]\n",
    "    elif column_name.startswith(\"s_\"):\n",
    "        return tpch_table_sizes[\"supplier\"]\n",
    "    elif column_name.startswith(\"n_\"):\n",
    "        return tpch_table_sizes[\"nation\"]\n",
    "    elif column_name.startswith(\"r_\"):\n",
    "        return tpch_table_sizes[\"region\"]\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_table_name(column_name):\n",
    "    if column_name.startswith(\"c_\"):\n",
    "        return \"customer\"\n",
    "    elif column_name.startswith(\"l_\"):\n",
    "        return \"lineitem\"\n",
    "    elif column_name.startswith(\"o_\"):\n",
    "        return \"orders\"\n",
    "    elif column_name.startswith(\"p_\"):\n",
    "        return \"part\"\n",
    "    elif column_name.startswith(\"ps_\"):\n",
    "        return \"partsupp\"\n",
    "    elif column_name.startswith(\"s_\"):\n",
    "        return \"supplier\"\n",
    "    elif column_name.startswith(\"n_\"):\n",
    "        return \"nation\"\n",
    "    elif column_name.startswith(\"r_\"):\n",
    "        return \"region\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "    \n",
    "results_df[\"Table size\"] = results_df.apply(lambda row: get_table_size(row[\"Materialization\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rank and percentile within query and globally\n",
    "# Sort by query and time gain, then add rank within each query group\n",
    "results_df['Query Rank'] = results_df.groupby('Query')['Improvement'].rank(ascending=False).astype(int)\n",
    "\n",
    "# Calculate percentage rank within each query group (0-100%)\n",
    "results_df['Query Percentile'] = results_df.groupby('Query')['Improvement'].rank(pct=True).round(2)\n",
    "\n",
    "# Sort by query and time gain, then add rank within each query group\n",
    "results_df['Global Rank'] = results_df['Improvement'].rank(ascending=False).astype(int)\n",
    "\n",
    "# Calculate percentage rank within each query group (0-100%)\n",
    "results_df['Global Percentile'] = results_df['Improvement'].rank(pct=True).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by improvement\n",
    "results_df.sort_values(\"Improvement\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add query usage frequency\n",
    "def get_field_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used()\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_join_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used_in_join()\n",
    "    if materialized_column in cols:\n",
    "        return len(cols[materialized_column])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_field_where_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used_with_position()[\"where\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_select_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used_with_position()[\"select\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_group_by_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used_with_position()[\"group_by\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_field_order_by_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used_with_position()[\"order_by\"]\n",
    "    return cols.count(materialized_column)\n",
    "\n",
    "def get_self_join_frequency_for_query(query_name, materialized_column):\n",
    "    q = QUERIES[query_name]\n",
    "    cols = q.columns_used_with_position()\n",
    "    if \"self_join\" in cols and materialized_column in cols[\"self_join\"].keys():\n",
    "        return cols[\"self_join\"][materialized_column]\n",
    "    return 0\n",
    "\n",
    "\n",
    "results_df[\"Total Frequency\"] = results_df.apply(\n",
    "    lambda row: get_field_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Join Frequency\"] = results_df.apply(\n",
    "    lambda row: get_field_join_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Where Frequency\"] = results_df.apply(\n",
    "    lambda row: get_field_where_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Select Frequency\"] = results_df.apply(\n",
    "    lambda row: get_field_select_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n",
    "results_df[\"Group By Frequency\"] = results_df.apply(\n",
    "    lambda row: get_field_group_by_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n",
    "results_df[\"Order By Frequency\"] = results_df.apply(\n",
    "    lambda row: get_field_order_by_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n",
    "\n",
    "results_df[\"Self Join Frequency\"] = results_df.apply(\n",
    "    lambda row: get_self_join_frequency_for_query(row[\"Query\"], row[\"Materialization\"]), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[(results_df[\"Query\"] == 'q11') & (results_df[\"Materialization\"] == 'ps_suppkey')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Values\n",
    "Some of the materializations give negative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = -0.05\n",
    "negative_improvement_df = results_df[results_df[\"Improvement\"] < treshold]\n",
    "print(f'There are {len(negative_improvement_df)} with improvement less than {treshold}')\n",
    "print(f'The queries with negative improvmement are {negative_improvement_df[\"Query\"].unique()}')\n",
    "print(f'The fields whose improvement was negative are {negative_improvement_df[\"Materialization\"].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Single Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_join_df = results_df[(results_df[\"Join Frequency\"] == 1) & (results_df[\"Where Frequency\"] == 0)]\n",
    "sj_negative_improvement_df = single_join_df[single_join_df[\"Improvement\"] < treshold]\n",
    "print(single_join_df[single_join_df[\"Global Percentile\"]>0.8][\"Query\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_q18 = single_join_df[(single_join_df[\"Query\"] == 'q18') & (single_join_df[\"Materialization\"] == 'l_orderkey')]\n",
    "\n",
    "# sj_q18 = single_join_df[single_join_df[\"Query\"] == 'q3']\n",
    "sj_q18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_q18.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(sj_negative_improvement_df)} with improvement less than {treshold}')\n",
    "print(f'The queries with negative improvmement are {sj_negative_improvement_df[\"Query\"].unique()}')\n",
    "print(f'The fields whose improvement was negative are {sj_negative_improvement_df[\"Materialization\"].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_where_df = results_df[(results_df[\"Join Frequency\"] == 0) & (results_df[\"Where Frequency\"] == 1)]\n",
    "print(single_where_df[single_where_df[\"Global Percentile\"]>0.8][\"Query\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_where_query_df = single_where_df[single_where_df[\"Query\"] == 'q16']\n",
    "single_where_query_df = single_where_query_df[single_where_query_df[\"Materialization\"] == 'ps_suppkey']\n",
    "# single_where_query_df[single_where_query_df[\"Materialization\"] == 'o_orderstatus'].head()\n",
    "# single_where_query_df[single_where_query_df[\"Previous Materializations\"] == \"['l_commitdate']\"]\n",
    "# single_where_query_df[single_where_query_df[\"Previous Materializations\"] == \"[]\"]\n",
    "# single_where_query_df[single_where_query_df[\"Materialization\"] == 'p_container']\n",
    "single_where_query_df\n",
    "# TODO 16 - ps_suppkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_where_query_df[single_where_df[\"Materialization\"] == 'o_orderstatus'].tail(25)\n",
    "single_where_query_df.tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to investigate \n",
    "q10, n_nationkey gives best performance when n_name materialized\n",
    "\n",
    "- q21, n_nationkey negative\n",
    "- q21, hvorfor er s_nationkey alltid dritbra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 1.5\n",
    "positive_df = results_df[results_df[\"Improvement\"] > treshold]\n",
    "print(f'There are {len(positive_df)} with improvement less than {treshold}')\n",
    "print(f'The queries with negative improvmement are {positive_df[\"Query\"].unique()}')\n",
    "print(f'The fields whose improvement was negative are {positive_df[\"Materialization\"].unique()}')\n",
    "positive_df[positive_df['Query'] == 'q20'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries\n",
    "Print queries and materialization queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_names = ['q14']\n",
    "# materializations = [['l_orderkey'], ['l_orderkey', 'o_custkey'], ['o_orderkey'], ['o_orderkey', 'o_custkey'],['o_totalprice'], ['o_totalprice', 'o_custkey'] ]\n",
    "# materializations = [['o_custkey', 's_nationkey'], ['o_custkey', 's_nationkey', 'o_orderkey'], ['l_discount', 's_nationkey'], ['l_discount', 's_nationkey', 'o_orderkey']]\n",
    "# materializations = [[],['s_nationkey']]\n",
    "materializations = [['delete_status_userIdStr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for materialization in materializations:\n",
    "    for query_name in query_names:\n",
    "        query_obj = QUERIES[query_name]\n",
    "        m = 0\n",
    "        update_stmt = \"UPDATE test_table SET \"\n",
    "        print(f\"################# {query_name.upper()}, {materialization} #################\")\n",
    "        for field in materialization:\n",
    "            field_obj = COLUMN_MAP[field]\n",
    "\n",
    "            print(f\"ALTER TABLE test_table DROP COLUMN IF EXISTS {field};\")\n",
    "            print(f\"ALTER TABLE test_table ADD {field} {field_obj['type']};\")\n",
    "            update_stmt += f\"{field} = {field_obj['access']}, \"\n",
    "        update_stmt = update_stmt[:-2] + \";\"\n",
    "        print(update_stmt)\n",
    "        # Create the field-materialization setup for this test\n",
    "        fields = []\n",
    "        for field, access_query in COLUMN_MAP.items():\n",
    "            fields.append(\n",
    "                (field, access_query, field in materialization))\n",
    "        \n",
    "        print(QUERIES[query_name].get_query(fields=fields))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
