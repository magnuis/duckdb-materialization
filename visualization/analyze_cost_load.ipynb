{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from testing.tpch import setup as tpch_setup\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"cmr10\"\n",
    "plt.rcParams[\"font.serif\"] = [\"cmr10\"]\n",
    "plt.rcParams[\"font.size\"] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 2\n",
    "\n",
    "TPCH_TABLE_SIZES = {\n",
    "    \"lineitem\": int(6000000 * SCALE_FACTOR),\n",
    "    \"orders\": int(1500000 * SCALE_FACTOR),\n",
    "    \"partsupp\": int(800000 * SCALE_FACTOR),\n",
    "    \"part\": int(200000 * SCALE_FACTOR),\n",
    "    \"customer\": int(150000 * SCALE_FACTOR),\n",
    "    \"supplier\": int(10000 * SCALE_FACTOR),\n",
    "    \"nation\": 25,  # Not scaled\n",
    "    \"region\": 5    # Not scaled\n",
    "}\n",
    "\n",
    "TPCH_TABLE_PROPORTIONS = {\n",
    "    \"customer\": TPCH_TABLE_SIZES[\"customer\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"lineitem\": TPCH_TABLE_SIZES[\"lineitem\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"orders\": TPCH_TABLE_SIZES[\"orders\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"part\": TPCH_TABLE_SIZES[\"part\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"partsupp\": TPCH_TABLE_SIZES[\"partsupp\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"supplier\": TPCH_TABLE_SIZES[\"supplier\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"nation\": TPCH_TABLE_SIZES[\"nation\"] / sum(TPCH_TABLE_SIZES.values()),\n",
    "    \"region\": TPCH_TABLE_SIZES[\"region\"] / sum(TPCH_TABLE_SIZES.values())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_prefix_to_name = {\n",
    "    \"ps\": \"partsupp\",\n",
    "    \"c\": \"customer\",\n",
    "    \"l\": \"lineitem\",\n",
    "    \"n\": \"nation\",\n",
    "    \"o\": \"orders\",\n",
    "    \"p\": \"part\",\n",
    "    \"r\": \"region\",\n",
    "    \"s\": \"supplier\",\n",
    "}\n",
    "\n",
    "def get_table_name(field):\n",
    "    prefix = field.split(\"_\")[0]\n",
    "    return table_prefix_to_name.get(prefix, \"Unknown\")\n",
    "\n",
    "def get_table_size(table):\n",
    "    return TPCH_TABLE_SIZES[table]\n",
    "\n",
    "def get_table_proportions(table_name):\n",
    "    return TPCH_TABLE_PROPORTIONS.get(table_name, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_write_load_df():\n",
    "    # RESULTS_PATH = f\"{os.curdir}/results/load-based-N-fields/tpch/2025-03-26-15H/\"\n",
    "    # Read each line as a JSON document since columns vary\n",
    "    RESULTS_PATH = f\"{os.curdir}/results/write-performance/final/\"\n",
    "    write_load_df = pd.read_csv(RESULTS_PATH + \"write_times.csv\")\n",
    "    write_load_df[\"Document Table\"] = write_load_df.apply(lambda row: next(col.split('_')[0] for col in row.index if pd.notna(row[col])), axis=1)\n",
    "    write_load_df[\"Document Table\"] = write_load_df[\"Document Table\"].apply(get_table_name)\n",
    "\n",
    "    return write_load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_types(results_df):\n",
    "    results_df[\"Column Type\"] = results_df.apply(\n",
    "        lambda row: tpch_setup.COLUMN_MAP[row[\"Test\"]][\"type\"]\n",
    "        if row[\"Test\"] in tpch_setup.COLUMN_MAP else \"Unknown\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def add_field_frequency_in_TPCH(results_df):\n",
    "    results_df[\"Field Frequency\"] = results_df.apply(lambda row: get_field_frequency_in_TPCH(row[\"Table Name\"]), axis=1)\n",
    "    return results_df\n",
    "\n",
    "def get_field_frequency_in_TPCH(table_name):\n",
    "    return get_table_proportions(table_name)\n",
    "\n",
    "def add_table_name(results_df):\n",
    "    results_df[\"Table Name\"] = results_df.apply(lambda row: get_table_name(row[\"Test\"]), axis=1)\n",
    "    return results_df\n",
    "\n",
    "def add_table_size(results_df):\n",
    "    results_df[\"Table Size\"] = results_df.apply(lambda row: get_table_size(row[\"Table Name\"]), axis=1)\n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_df():\n",
    "    # RESULTS_PATH = f\"{os.curdir}/results/load-based-N-fields/tpch/2025-03-26-15H/\"\n",
    "    # results_df = pd.read_csv(RESULTS_PATH + \"write_times.csv\")\n",
    "    RESULTS_PATH = f\"{os.curdir}/results/write-performance/final/\"\n",
    "    results_df = pd.read_csv(RESULTS_PATH + \"write_times.csv\")\n",
    "\n",
    "    # Clean up any unnamed columns\n",
    "    if \"Unnamed: 0\" in results_df.columns:\n",
    "        results_df = results_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "    # Change name of Write time to Write Time\n",
    "    results_df = results_df.rename(columns={\"Write time\": \"Write Time\"})\n",
    "\n",
    "\n",
    "    # Parse previous materializations into list\n",
    "    results_df[\"Materialization\"] = results_df[\"Materialization\"].apply(\n",
    "        lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    "    )\n",
    "\n",
    "    # # Parse DB Size into tuple of ints\n",
    "    # results_df[\"DB Size\"] = results_df[\"DB Size\"].apply(\n",
    "    #     lambda x: tuple(map(int, x.strip('()').strip().split(', ')))\n",
    "    # )\n",
    "\n",
    "    # results_df[\"DB Size N Blocks\"] = results_df[\"DB Size\"].apply(lambda x: x[0])\n",
    "\n",
    "    for col in results_df.columns:\n",
    "        print(col)\n",
    "\n",
    "        # Parse DB Size into tuple of ints\n",
    "    results_df[\"DB Size Before\"] = results_df[\"DB Size Before\"].apply(\n",
    "        lambda x: tuple(map(int, x.strip('()').strip().split(', ')))\n",
    "    )\n",
    "\n",
    "    # Parse DB Size into tuple of ints\n",
    "    results_df[\"DB Size After\"] = results_df[\"DB Size After\"].apply(\n",
    "        lambda x: tuple(map(int, x.strip('()').strip().split(', ')))\n",
    "    )\n",
    "\n",
    "    results_df[\"DB Size Before N Blocks\"] = results_df[\"DB Size Before\"].apply(lambda x: x[0])\n",
    "    results_df[\"DB Size After N Blocks\"] = results_df[\"DB Size After\"].apply(lambda x: x[0])\n",
    "    results_df[\"DB Size N Blocks Increase\"] = results_df[\"DB Size After N Blocks\"] - results_df[\"DB Size Before N Blocks\"]\n",
    "\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "def add_number_materialized_fields(df):\n",
    "    df[\"N Materialized Fields\"] = df[\"Materialization\"].apply(len)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(x, y, title, xlabel, ylabel, colorby=None, cmap='tab10', alpha=0.5, figsize=(12, 8)):\n",
    "    \"\"\"Create a scatter plot with optional color coding\"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    if colorby is not None:\n",
    "        categories = colorby.astype('category').cat.codes\n",
    "        scatter = plt.scatter(x, y, c=categories, alpha=alpha, cmap=cmap)\n",
    "\n",
    "        # Add colorbar\n",
    "        colorbar = plt.colorbar()\n",
    "        colorbar.set_ticks(range(len(colorby.unique())))\n",
    "        colorbar.set_ticklabels(sorted(colorby.unique()))\n",
    "    else:\n",
    "        scatter = plt.scatter(x, y, alpha=alpha)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add grid\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_violin(data_dict, title, xlabel, ylabel, figsize=(12, 8), showmeans=True):\n",
    "    \"\"\"Create a violin plot from a dictionary of data\"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "\n",
    "    # Convert dict values to list\n",
    "    data_values = list(data_dict.values())\n",
    "\n",
    "    # Create violin plot\n",
    "    violin_plot = plt.violinplot(data_values, showmeans=showmeans)\n",
    "\n",
    "    # Set x-axis ticks and labels\n",
    "    plt.xticks(\n",
    "        range(1, len(data_dict) + 1),\n",
    "        list(data_dict.keys()),\n",
    "        rotation=45,\n",
    "        ha='right'\n",
    "    )\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add counts above each violin\n",
    "    ax = plt.gca()\n",
    "    try:\n",
    "        max_height = max([max(v) if len(v) > 0 else 0 for v in data_values])\n",
    "        # Get the current y-axis limits\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        # Place text just below the upper limit\n",
    "        text_y = ymax - (ymax - ymin) * 0.02\n",
    "        for i, (key, values) in enumerate(data_dict.items(), 1):\n",
    "            ax.text(i, text_y,\n",
    "                    f'n={len(values)}', ha='center', va='top')\n",
    "    except ValueError:\n",
    "        # Handle empty data\n",
    "        pass\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, plt.gca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = load_results_df()\n",
    "results_df = add_number_materialized_fields(results_df)\n",
    "\n",
    "results_df = results_df[(results_df[\"Test\"].str.startswith(\"frequ\")) | (results_df[\"Test\"] == \"no_materialization\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_load_df = load_write_load_df()\n",
    "write_load_table_df = write_load_df[\"Document Table\"]\n",
    "\n",
    "# Et lite problem her er at fordelingen er helt jevn. Det gjør det veldig vanskelig å se effekten av frekvens.\n",
    "write_load_count = write_load_df[\"Document Table\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_scatter(\n",
    "    results_df[\"N Materialized Fields\"],\n",
    "    results_df[\"DB Size After N Blocks\"],\n",
    "    \"Database Size / Number of Materialized Fields\", \n",
    "    \"Number of Materialized Fields\",\n",
    "    \"Database Size (Data Blocks)\",\n",
    "    colorby=results_df[\"Load\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materialization time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_scatter(\n",
    "    results_df[\"N Materialized Fields\"],\n",
    "    results_df[\"Materialization Time\"],\n",
    "    \"Time to Materialize / Number of Materialized Fields\",\n",
    "    \"Number of Materialized Fields\",\n",
    "    \"Materialization Time (s)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_scatter(\n",
    "    results_df[\"N Materialized Fields\"],\n",
    "    results_df[\"Write Time\"],\n",
    "    \"Time to Write 5000 Documents / Number of Materialized Fields\",\n",
    "    \"Number of Materialized Fields\",\n",
    "    \"Write Time (s)\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
